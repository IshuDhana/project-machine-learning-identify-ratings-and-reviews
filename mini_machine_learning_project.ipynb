{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPhg1yGO2OGDtYtNNXp2qR8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IshuDhana/Mini_project_1/blob/main/mini_machine_learning_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports details"
      ],
      "metadata": {
        "id": "AQ0LmQUEOpKr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import (\n",
        "    train_test_split, TimeSeriesSplit, KFold, cross_val_score\n",
        ")\n",
        "from sklearn.metrics import (\n",
        "    mean_squared_error, r2_score, mean_absolute_error\n",
        ")\n"
      ],
      "metadata": {
        "id": "4AHV0VMUOzeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Training Data"
      ],
      "metadata": {
        "id": "-0p0I5R8Tfo3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_file = pd.read_csv(\"training.csv\")\n",
        "\n",
        "print(\"=== Training Data Preview ===\")\n",
        "print(df_file.head(), \"\\n\")\n",
        "\n",
        "print(\"=== Training Data Info ===\")\n",
        "print(df_file.info(), \"\\n\")\n",
        "\n",
        "print(\"=== Summary Statistics ===\")\n",
        "print(df_file.describe(), \"\\n\")"
      ],
      "metadata": {
        "id": "9WRkqjI0Tk17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Cleaning & Preprocessing"
      ],
      "metadata": {
        "id": "UJmUOSurTnlH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop junk columns\n",
        "df_file = df_file.loc[:, ~df_file.columns.str.contains(r'^Unnamed')]\n",
        "\n",
        "# Parse date\n",
        "df_file['date'] = pd.to_datetime(df_file['date'], errors='coerce')\n",
        "df_file.dropna(subset=[\"date\"], inplace=True)\n",
        "\n",
        "# Normalize state_holiday\n",
        "sh = (\n",
        "    df_file['state_holiday']\n",
        "    .astype(str).str.strip().str.lower()\n",
        "    .replace({'false': '0', 'none': '0', 'nan': '0'})\n",
        ")\n",
        "df_file['state_holiday'] = pd.Categorical(sh, categories=['0', 'a', 'b', 'c'])\n",
        "\n",
        "print(df_file.isna().sum())"
      ],
      "metadata": {
        "id": "bAqEAeeaTp9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature / Target Split"
      ],
      "metadata": {
        "id": "x0cv9w47TrYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_file.drop(\"sales\", axis=1)\n",
        "y = df_file[\"sales\"]"
      ],
      "metadata": {
        "id": "UQNLIcS2TuRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scaling Numeric Features"
      ],
      "metadata": {
        "id": "Afmq78F5TvOD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "\n",
        "X_numeric = X.drop(columns=['date', 'state_holiday'])\n",
        "X_scaled = scaler.fit_transform(X_numeric)\n",
        "\n",
        "X_scaled_df = pd.DataFrame(X_scaled, columns=X_numeric.columns)\n",
        "X_scaled_df = pd.concat(\n",
        "    [X[['date', 'state_holiday']].reset_index(drop=True), X_scaled_df],\n",
        "    axis=1\n",
        ")"
      ],
      "metadata": {
        "id": "IiFrJk60TxuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train/Test Split (Random)"
      ],
      "metadata": {
        "id": "GxmSdmzTT0eX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "iog9YesMT19j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Time Series Cross-Validation"
      ],
      "metadata": {
        "id": "d__ZFB6pT3bk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_ts = X.copy()\n",
        "for c in ['date', 'state_holiday']:\n",
        "    if c in X_ts.columns:\n",
        "        X_ts = X_ts.drop(columns=[c])\n",
        "\n",
        "X_ts = X_ts.reset_index(drop=True)\n",
        "y_ts = y.reset_index(drop=True)\n",
        "\n",
        "tscv = TimeSeriesSplit(n_splits=5)\n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('model', RandomForestRegressor(\n",
        "        n_estimators=200,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    ))\n",
        "])\n",
        "\n",
        "mse_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(tscv.split(X_ts), start=1):\n",
        "    X_train, X_test = X_ts.iloc[train_idx], X_ts.iloc[test_idx]\n",
        "    y_train, y_test = y_ts.iloc[train_idx], y_ts.iloc[test_idx]\n",
        "\n",
        "    pipe.fit(X_train, y_train)\n",
        "    y_pred = pipe.predict(X_test)\n",
        "\n",
        "    mse_scores.append(mean_squared_error(y_test, y_pred))\n",
        "    r2_scores.append(r2_score(y_test, y_pred))\n",
        "\n",
        "    print(f\"Fold {fold}: MSE={mse_scores[-1]:.4f}, R2={r2_scores[-1]:.4f}\")\n",
        "\n",
        "print(\"Average MSE:\", np.mean(mse_scores))\n",
        "print(\"Average R2:\", np.mean(r2_scores))\n",
        "\n",
        "# Fit final model\n",
        "pipe.fit(X_ts, y_ts)\n",
        "final_model = pipe"
      ],
      "metadata": {
        "id": "Zb3OPyIcT7qM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression Model"
      ],
      "metadata": {
        "id": "vcihgMtZT9Pg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"Intercept:\", model.intercept_)\n",
        "print(\"Coefficients:\", model.coef_)\n",
        "\n",
        "print(\"\\nTrain/Test Evaluation:\")\n",
        "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
        "print(\"MAE:\", mean_absolute_error(y_test, y_pred))\n",
        "print(\"R2:\", r2_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "SRDnbYwtT-0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K-Fold Cross Validation"
      ],
      "metadata": {
        "id": "ygxJxMG5UBeu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "mse_scores = -cross_val_score(\n",
        "    model, X_scaled, y, cv=kf,\n",
        "    scoring='neg_mean_squared_error'\n",
        ")\n",
        "r2_scores = cross_val_score(\n",
        "    model, X_scaled, y, cv=kf,\n",
        "    scoring='r2'\n",
        ")\n",
        "\n",
        "print(\"\\nK-Fold Cross Validation:\")\n",
        "print(\"Average MSE:\", mse_scores.mean())\n",
        "print(\"Average R2:\", r2_scores.mean())"
      ],
      "metadata": {
        "id": "okHbWfA-UEXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Real Data & Predict"
      ],
      "metadata": {
        "id": "Lr4gs4SgUGHk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_real_file = pd.read_csv(\"REAL_DATA.csv\")\n",
        "\n",
        "df_real_file = df_real_file.loc[:, ~df_real_file.columns.str.contains(r'^Unnamed')]\n",
        "df_real_file['date'] = pd.to_datetime(df_real_file['date'], errors='coerce')\n",
        "df_real_file.dropna(subset=[\"date\"], inplace=True)\n",
        "\n",
        "sh = (\n",
        "    df_real_file['state_holiday']\n",
        "    .astype(str).str.strip().str.lower()\n",
        "    .replace({'false': '0', 'none': '0', 'nan': '0'})\n",
        ")\n",
        "df_real_file['state_holiday'] = pd.Categorical(sh, categories=['0', 'a', 'b', 'c'])\n",
        "\n",
        "train_cols = X_ts.columns.tolist()\n",
        "_real_temp = df_real_file.copy()\n",
        "\n",
        "for c in ['date', 'state_holiday']:\n",
        "    if c in _real_temp.columns and c not in train_cols:\n",
        "        _real_temp = _real_temp.drop(columns=[c])\n",
        "\n",
        "X_real = _real_temp.reindex(columns=train_cols).fillna(0)\n",
        "\n",
        "df_real_file['sales_pred'] = pipe.predict(X_real)\n",
        "\n",
        "print(df_real_file.head())"
      ],
      "metadata": {
        "id": "k0quW7QgUJHM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}